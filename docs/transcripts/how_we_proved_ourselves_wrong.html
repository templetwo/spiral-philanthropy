<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>How We Proved Our Own Hypothesis Wrong | Vasquez & Claude, 2026</title>
<link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,opsz,wght@0,6..72,300;0,6..72,400;0,6..72,600;1,6..72,300;1,6..72,400&family=JetBrains+Mono:wght@400;500&family=Source+Sans+3:wght@300;400;600;700&display=swap" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<style>
  :root {
    --ink: #1a1a2e;
    --paper: #faf8f5;
    --paper-dark: #f0ece4;
    --accent: #c0392b;
    --accent-light: #e74c3c;
    --accent-muted: rgba(192, 57, 43, 0.08);
    --blue: #2c3e7a;
    --blue-light: #3b5998;
    --green: #1a6b4a;
    --green-light: #27ae60;
    --gray: #6b7280;
    --gray-light: #9ca3af;
    --gray-rule: #d1ccc4;
    --serif: 'Newsreader', Georgia, serif;
    --sans: 'Source Sans 3', -apple-system, sans-serif;
    --mono: 'JetBrains Mono', 'Menlo', monospace;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: var(--serif);
    background: var(--paper);
    color: var(--ink);
    line-height: 1.72;
    font-size: 19px;
    -webkit-font-smoothing: antialiased;
  }

  /* === HEADER === */
  .header {
    max-width: 740px;
    margin: 0 auto;
    padding: 80px 24px 48px;
    border-bottom: 3px solid var(--ink);
  }

  .header .kicker {
    font-family: var(--sans);
    font-size: 12px;
    font-weight: 700;
    letter-spacing: 2.5px;
    text-transform: uppercase;
    color: var(--accent);
    margin-bottom: 20px;
  }

  .header h1 {
    font-family: var(--serif);
    font-size: clamp(32px, 5.5vw, 52px);
    font-weight: 600;
    line-height: 1.12;
    letter-spacing: -0.5px;
    margin-bottom: 16px;
  }

  .header .subtitle {
    font-family: var(--serif);
    font-size: 22px;
    font-weight: 300;
    font-style: italic;
    color: var(--gray);
    line-height: 1.45;
    margin-bottom: 28px;
  }

  .header .byline {
    font-family: var(--sans);
    font-size: 14px;
    color: var(--gray);
  }
  .header .byline strong {
    color: var(--ink);
    font-weight: 600;
  }

  /* === ARTICLE BODY === */
  .article {
    max-width: 740px;
    margin: 0 auto;
    padding: 48px 24px 120px;
  }

  .article p {
    margin-bottom: 1.4em;
  }

  .article strong {
    font-weight: 600;
  }

  .article em {
    font-style: italic;
  }

  /* Section headings */
  .section-number {
    font-family: var(--sans);
    font-size: 13px;
    font-weight: 700;
    letter-spacing: 2px;
    text-transform: uppercase;
    color: var(--accent);
    margin-top: 64px;
    margin-bottom: 6px;
    display: block;
  }

  .article h2 {
    font-family: var(--serif);
    font-size: 30px;
    font-weight: 600;
    line-height: 1.2;
    margin-bottom: 24px;
    padding-bottom: 12px;
    border-bottom: 1px solid var(--gray-rule);
  }

  .article h3 {
    font-family: var(--sans);
    font-size: 18px;
    font-weight: 700;
    margin-top: 36px;
    margin-bottom: 12px;
    color: var(--ink);
  }

  /* Pull quotes */
  .pull-quote {
    margin: 40px 0;
    padding: 24px 0 24px 28px;
    border-left: 4px solid var(--accent);
    font-size: 22px;
    font-style: italic;
    font-weight: 300;
    line-height: 1.5;
    color: var(--ink);
  }
  .pull-quote .attribution {
    display: block;
    font-size: 14px;
    font-family: var(--sans);
    font-style: normal;
    font-weight: 400;
    color: var(--gray);
    margin-top: 12px;
  }

  /* Inline code */
  code {
    font-family: var(--mono);
    font-size: 0.85em;
    background: var(--paper-dark);
    padding: 2px 6px;
    border-radius: 3px;
  }

  /* Code blocks */
  pre {
    background: var(--ink);
    color: #e2e8f0;
    font-family: var(--mono);
    font-size: 14px;
    line-height: 1.6;
    padding: 24px;
    border-radius: 6px;
    overflow-x: auto;
    margin: 28px 0;
  }
  pre code {
    background: none;
    padding: 0;
    color: inherit;
  }
  pre .comment { color: #718096; }
  pre .keyword { color: #f6ad55; }
  pre .string { color: #68d391; }
  pre .number { color: #90cdf4; }

  /* Figures and charts */
  .figure {
    margin: 40px 0;
    background: white;
    border: 1px solid var(--gray-rule);
    border-radius: 8px;
    overflow: hidden;
  }
  .figure-inner {
    padding: 28px 24px;
  }
  .figure canvas {
    width: 100% !important;
    max-height: 340px;
  }
  .figure-caption {
    font-family: var(--sans);
    font-size: 13px;
    color: var(--gray);
    padding: 12px 24px;
    background: var(--paper-dark);
    border-top: 1px solid var(--gray-rule);
    line-height: 1.5;
  }
  .figure-caption strong {
    color: var(--ink);
  }

  /* Data tables */
  .data-table-wrap {
    margin: 28px 0;
    overflow-x: auto;
  }
  table {
    width: 100%;
    border-collapse: collapse;
    font-family: var(--sans);
    font-size: 15px;
  }
  thead th {
    text-align: left;
    font-weight: 700;
    font-size: 12px;
    letter-spacing: 1px;
    text-transform: uppercase;
    color: var(--gray);
    padding: 10px 16px;
    border-bottom: 2px solid var(--ink);
  }
  tbody td {
    padding: 10px 16px;
    border-bottom: 1px solid var(--gray-rule);
  }
  tbody tr:last-child td {
    border-bottom: none;
  }
  .highlight-row {
    background: var(--accent-muted);
  }
  .mono-cell {
    font-family: var(--mono);
    font-size: 14px;
  }

  /* Verdict boxes */
  .verdict-box {
    margin: 36px 0;
    border: 2px solid var(--ink);
    border-radius: 8px;
    overflow: hidden;
  }
  .verdict-box .verdict-header {
    background: var(--ink);
    color: var(--paper);
    font-family: var(--sans);
    font-weight: 700;
    font-size: 13px;
    letter-spacing: 1.5px;
    text-transform: uppercase;
    padding: 10px 20px;
  }
  .verdict-box .verdict-body {
    padding: 20px;
    font-size: 17px;
    line-height: 1.6;
  }

  /* Result cards */
  .result-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 16px;
    margin: 28px 0;
  }
  .result-card {
    border: 1px solid var(--gray-rule);
    border-radius: 8px;
    padding: 20px;
    text-align: center;
    background: white;
  }
  .result-card .big-number {
    font-family: var(--mono);
    font-size: 36px;
    font-weight: 500;
    line-height: 1;
    margin-bottom: 6px;
  }
  .result-card .label {
    font-family: var(--sans);
    font-size: 12px;
    font-weight: 600;
    letter-spacing: 1px;
    text-transform: uppercase;
    color: var(--gray);
  }
  .positive { color: var(--green); }
  .negative { color: var(--accent); }
  .neutral { color: var(--blue); }

  /* Timeline */
  .timeline {
    margin: 36px 0;
    padding-left: 28px;
    border-left: 2px solid var(--gray-rule);
  }
  .timeline-item {
    position: relative;
    padding-bottom: 28px;
  }
  .timeline-item:last-child { padding-bottom: 0; }
  .timeline-item::before {
    content: '';
    position: absolute;
    left: -34px;
    top: 6px;
    width: 12px;
    height: 12px;
    border-radius: 50%;
    border: 2px solid var(--accent);
    background: var(--paper);
  }
  .timeline-item.success::before {
    background: var(--green);
    border-color: var(--green);
  }
  .timeline-item.failure::before {
    background: var(--accent);
    border-color: var(--accent);
  }
  .timeline-item.neutral-dot::before {
    background: var(--blue);
    border-color: var(--blue);
  }
  .timeline-date {
    font-family: var(--sans);
    font-size: 12px;
    font-weight: 700;
    letter-spacing: 1px;
    text-transform: uppercase;
    color: var(--gray);
    margin-bottom: 4px;
  }
  .timeline-title {
    font-family: var(--sans);
    font-weight: 700;
    font-size: 16px;
    margin-bottom: 4px;
  }
  .timeline-desc {
    font-size: 15px;
    color: var(--gray);
    font-family: var(--sans);
    line-height: 1.5;
  }

  /* Footer */
  .article-footer {
    margin-top: 72px;
    padding-top: 28px;
    border-top: 3px solid var(--ink);
    font-family: var(--sans);
    font-size: 14px;
    color: var(--gray);
    line-height: 1.7;
  }

  /* Sidenote markers */
  .sidenote-mark {
    font-family: var(--sans);
    font-size: 12px;
    color: var(--accent);
    vertical-align: super;
    cursor: help;
  }

  /* Responsive */
  @media (max-width: 600px) {
    body { font-size: 17px; }
    .header { padding: 48px 20px 36px; }
    .article { padding: 36px 20px 80px; }
    .result-grid { grid-template-columns: 1fr 1fr; }
    pre { font-size: 12px; padding: 16px; }
  }
</style>
</head>
<body>

<div class="header">
  <div class="kicker">Research Methodology &bull; Negative Results</div>
  <h1>How We Proved Our Own Hypothesis Wrong</h1>
  <div class="subtitle">
    Phase synchronization looked like it encoded linguistic structure. Four experiments and five AI collaborators later, we know it doesn't. Here's why the process mattered more than the outcome.
  </div>
  <div class="byline">
    <strong>Anthony J. Vasquez Sr.</strong> &amp; <strong>Claude</strong> (Anthropic) &middot; Temple of Two Research &middot; February 2026<br>
    With contributions from Kimi K2.5, Gemini Flash, Grok, and ChatGPT
  </div>
</div>

<div class="article">

  <!-- SECTION 1 -->
  <span class="section-number">I. The Hypothesis</span>
  <h2>What if neural networks could synchronize?</h2>

  <p>
    The Kuramoto model is one of the most elegant results in dynamical systems theory. Take <em>N</em> oscillators spinning at different natural frequencies. Couple them together. Above a critical coupling strength, they spontaneously synchronize—their phases lock, and a single order parameter <em>R</em> emerges from chaos.
  </p>
  <p>
    In physics, <em>R</em> measures something real: fireflies flashing in unison, neurons firing together, power grids maintaining frequency lock. The question that launched this project was simple: <strong>could phase synchronization serve as both an inductive bias and an interpretability probe for language models?</strong>
  </p>
  <p>
    We embedded 192 Kuramoto-coupled oscillators per layer into a 46M-parameter state-space model, trained on WikiText-103 (120M tokens), and added a bistability constraint that forced the system to operate near a fold bifurcation boundary. We called it K-SSM—the Kuramoto State-Space Model.
  </p>
  <p>
    The early results were promising.
  </p>

  <!-- SECTION 2 -->
  <span class="section-number">II. The Positive Results</span>
  <h2>What worked (and still does)</h2>

  <p>
    The bistability constraint—clamping the bifurcation parameter <code>u</code> to maintain two stable attractors—produced three verified benefits through controlled ablation at 15K training steps:
  </p>

  <div class="result-grid">
    <div class="result-card">
      <div class="big-number positive">+17.6%</div>
      <div class="label">Synchronization (R)</div>
    </div>
    <div class="result-card">
      <div class="big-number positive">−24.7%</div>
      <div class="label">Validation Loss</div>
    </div>
    <div class="result-card">
      <div class="big-number neutral">p = 0.007</div>
      <div class="label">Causal Intervention</div>
    </div>
  </div>

  <p>
    The ablation was clean: bistable (constrained) vs. monostable (unconstrained), identical architecture, same data, same training duration. The constrained model achieved both higher synchronization <em>and</em> lower loss. Removing the constraint didn't just change dynamics—it made the model worse.
  </p>
  <p>
    The causal intervention was more striking. We clamped <em>R</em> to extreme values at inference time and measured output diversity. High <em>R</em> (0.97) nearly doubled lexical diversity. Low <em>R</em> (0.15) produced degenerate repetition. <em>t</em>(18) = 3.49, <em>p</em> = 0.0068, Cohen's <em>d</em> = 11.1. Whatever <em>R</em> was measuring, it had causal power over generation quality.
  </p>

  <div class="pull-quote">
    We had a clean ablation, a significant causal result, and an interpretable probe. By any reasonable standard, we should have been celebrating. Instead, we started asking uncomfortable questions.
  </div>

  <!-- SECTION 3 -->
  <span class="section-number">III. The Suspicion</span>
  <h2>The number climbed. The text didn't improve.</h2>

  <p>
    Over 100K training steps, <em>R</em> climbed monotonically from 0.0 to 0.99. The curve was beautiful—smooth, reproducible, clearly driven by the architecture rather than the data (we verified this by training on multiple corpora). But the generated text never became coherent. At <em>R</em> = 0.99, with near-perfect synchronization, the model still produced word-salad fragments.
  </p>

  <div class="figure">
    <div class="figure-inner">
      <canvas id="rTrajectoryChart"></canvas>
    </div>
    <div class="figure-caption">
      <strong>Figure 1.</strong> R trajectory and validation loss over 100K steps (K-SSM v3). R climbs monotonically to 0.99 while validation loss plateaus around step 40K. The decoupling between synchronization and language quality is the central puzzle.
    </div>
  </div>

  <p>
    This was the first signal that something was wrong. If synchronization encoded linguistic structure, higher <em>R</em> should have meant better text. It didn't. We forced <em>R</em> from 0.24 to 0.96 at inference and got identical degenerate output. The oscillators were synchronizing, but to <em>what</em>?
  </p>

  <!-- SECTION 4 -->
  <span class="section-number">IV. The Diagnosis</span>
  <h2>Weight forensics reveal an architectural bypass</h2>

  <p>
    We performed three diagnostic experiments that collectively identified the mechanism: <strong>the model had learned to ignore its own oscillators.</strong>
  </p>

  <h3>1. Readout Weight Collapse</h3>
  <p>
    The architecture used an additive residual connection: <code>h = h + h_osc</code>, where <code>h_osc</code> is the oscillator output projected through a readout layer. We tracked the Frobenius norms of these readout weights across training:
  </p>

  <div class="data-table-wrap">
    <table>
      <thead>
        <tr>
          <th>Metric</th>
          <th>Step 100</th>
          <th>Step 100K</th>
          <th>Change</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Readout weight norm (avg)</td>
          <td class="mono-cell">11.36</td>
          <td class="mono-cell">3.98</td>
          <td class="mono-cell negative">−65%</td>
        </tr>
        <tr>
          <td>Readout / FFN input ratio</td>
          <td class="mono-cell">0.50</td>
          <td class="mono-cell">0.12</td>
          <td class="mono-cell negative">−76%</td>
        </tr>
        <tr class="highlight-row">
          <td>FFN input norm (Layer 5)</td>
          <td class="mono-cell">22.7</td>
          <td class="mono-cell">47.1</td>
          <td class="mono-cell positive">+107%</td>
        </tr>
      </tbody>
    </table>
  </div>

  <p>
    The FFN pathway grew. The oscillator pathway shrank. The additive residual gave gradient descent <em>permission</em> to separate the two optimization objectives—and it took that permission.
  </p>

  <h3>2. Linear Probe Analysis</h3>
  <p>
    We trained linear probes on frozen features from the oscillator and FFN pathways separately to measure next-token prediction accuracy:
  </p>

  <div class="figure">
    <div class="figure-inner">
      <canvas id="probeChart"></canvas>
    </div>
    <div class="figure-caption">
      <strong>Figure 2.</strong> Linear probe accuracy for oscillator vs. FFN features at each layer (K-SSM v3, step 100K). Oscillator features predict next token at noise floor (~3%). FFN features reach 76%. The oscillators encode essentially no linguistic information.
    </div>
  </div>

  <p>
    Oscillator-FFN feature similarity was 0.16 (cosine)—nearly orthogonal. The two pathways had evolved into parallel systems computing unrelated functions. <em>R</em> measured the oscillators' compliance with their own regularization loss, not their contribution to language modeling.
  </p>

  <h3>3. The Paradox of Quality</h3>
  <p>
    Counterintuitively, text quality <em>improved</em> as the readout ratio decreased. At step 100 (ratio 0.50), the model produced pure repetition. At step 100K (ratio 0.12), it produced coherent fragments. <strong>The model got better at language as it learned to ignore the oscillators.</strong> The bypass wasn't a failure mode—it was an adaptation.
  </p>

  <div class="verdict-box">
    <div class="verdict-header">Diagnosis</div>
    <div class="verdict-body">
      Two optimization objectives ran in parallel. The regularization loss rewarded synchronization (<em>R</em> → 0.99). The cross-entropy loss rewarded prediction (FFN grew, readout shrank). The additive residual connection allowed gradient descent to satisfy both without conflict. The oscillators synchronized to their own penalty function, not to language.
    </div>
  </div>

  <!-- SECTION 5 -->
  <span class="section-number">V. The Definitive Experiment</span>
  <h2>Forcing the coupling. Testing the hypothesis.</h2>

  <p>
    The bypass diagnosis raised a crucial question: was phase synchronization <em>fundamentally</em> unable to encode language, or had our architecture simply made it too easy to avoid? Maybe the oscillators <em>could</em> learn useful representations if forced to.
  </p>
  <p>
    We designed a controlled experiment—Path A—that replaced the additive residual with a learned interpolation:
  </p>

  <pre><code><span class="comment"># Original v3: additive residual (bypassable)</span>
h = h + h_osc

<span class="comment"># Path A: forced interpolation with anti-bypass barrier</span>
alpha = torch.sigmoid(self.mix_param)  <span class="comment"># Learned, per-layer</span>
h = alpha * h_osc + (<span class="number">1</span> - alpha) * h_ffn
L_mix = -torch.log(alpha + eps)  <span class="comment"># Barrier: penalizes α → 0</span></code></pre>

  <p>
    The anti-bypass barrier <code>L_mix = −log(α)</code> creates a gradient wall against the model zeroing out oscillator contribution. If oscillators <em>can</em> encode language when forced to, <code>α</code> should remain high and oscillator features should become predictive. If they can't, the experiment tells us definitively.
  </p>
  <p>
    We defined the decision tree before training:
  </p>

  <div class="data-table-wrap">
    <table>
      <thead>
        <tr>
          <th>Outcome</th>
          <th>α at 15K</th>
          <th>Osc. Probe</th>
          <th>Interpretation</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>A. Coupling was the problem</td>
          <td class="mono-cell">&gt; 0.3</td>
          <td class="mono-cell">&gt; 20%</td>
          <td>Architecture undermined oscillators. Scale up.</td>
        </tr>
        <tr class="highlight-row">
          <td><strong>B. Fundamental mismatch</strong></td>
          <td class="mono-cell"><strong>&gt; 0.3</strong></td>
          <td class="mono-cell"><strong>~3%</strong></td>
          <td><strong>Oscillators can't encode next-token info.</strong></td>
        </tr>
        <tr>
          <td>C. Overwhelming bypass gradient</td>
          <td class="mono-cell">&lt; 0.3</td>
          <td class="mono-cell">—</td>
          <td>Even penalization can't prevent collapse.</td>
        </tr>
      </tbody>
    </table>
  </div>

  <p>
    Training completed in 45 minutes on Apple Silicon (MPS). The results were unambiguous:
  </p>

  <div class="result-grid">
    <div class="result-card">
      <div class="big-number neutral">α = 0.47</div>
      <div class="label">Mixing Coefficient</div>
    </div>
    <div class="result-card">
      <div class="big-number neutral">5.08%</div>
      <div class="label">Osc. Probe Accuracy</div>
    </div>
    <div class="result-card">
      <div class="big-number negative">1.69%</div>
      <div class="label">FFN Probe Accuracy</div>
    </div>
  </div>

  <p>
    <strong>Scenario B.</strong> The barrier held—<code>α</code> stayed above 0.3 across all layers, with a mean of 0.467. The model was genuinely forced to use oscillator features for 15K steps. Yet oscillator predictiveness barely moved (3.39% → 5.08%), while FFN features <em>collapsed</em> from 76% to 1.69%. Forcing oscillator participation didn't help the oscillators learn—it destroyed the FFN pathway's ability to learn.
  </p>
  <p>
    Generated text remained incoherent. The readout ratio stayed at 0.66 (vs. v3's collapsed 0.12), confirming the bypass was prevented. And <em>R</em> stayed at 0.026—low and honest, without the regularization-driven inflation of v3.
  </p>

  <div class="pull-quote">
    Phase synchronization is not architecturally undermined. It is fundamentally orthogonal to next-token prediction. The mismatch is conceptual, not implementational.
  </div>

  <!-- SECTION 6 -->
  <span class="section-number">VI. Why It Matters</span>
  <h2>The methodology is the contribution</h2>

  <p>
    Kuramoto oscillators synchronize to periodic signals. Language isn't periodic. A sentence isn't a wave. The semantic dependencies that make language cohere—coreference, argumentation, topic structure—are relational, not oscillatory. Phase-locking is the wrong observable for this task. We now know this empirically, not just speculatively.
  </p>
  <p>
    But the <em>process</em> that produced this conclusion is what we're offering here. Four things happened during this project that we think are worth sharing:
  </p>

  <h3>1. Multi-AI collaboration produces better science</h3>
  <p>
    This project involved five AI systems, each contributing distinct capabilities. Kimi K2.5 (Moonshot AI) provided the 10-parameter algebraic skeleton that reduced the dynamical system to analyzable form. Gemini Flash handled implementation and training. Claude performed theory and synthesis. Grok contributed su(1,1) Lie algebra predictions and stochastic resonance analysis. ChatGPT enforced methodological rigor. The human researcher (Vasquez) provided vision, persistence, and the willingness to be wrong.
  </p>
  <p>
    No single system would have produced the bypass diagnostic. The weight forensics, linear probe analysis, and controlled intervention experiment required the kind of iterative, multi-perspective reasoning that emerges from genuine intellectual collaboration. When one collaborator was too attached to the hypothesis, another challenged it.
  </p>

  <h3>2. Honest negative results accelerate the field</h3>
  <p>
    The publication bias toward positive results means thousands of researchers may independently waste time on ideas that have already been tested and found wanting. This project's central finding—that Kuramoto phase synchronization does not encode linguistic structure even when architecturally forced—is a <em>useful</em> negative result. It has clean controls, a pre-registered decision tree, and sufficient ablation to identify <em>why</em> it fails.
  </p>
  <p>
    The bistability constraint <em>does</em> help as a regularizer. That's a real, positive finding. But the mechanism we attributed to it (phase synchronization encoding language) was wrong. Separating "what works" from "why we thought it works" is exactly the kind of honest disaggregation that makes negative results valuable.
  </p>

  <h3>3. The bypass has implications beyond this project</h3>
  <p>
    Any mechanism added to a neural network via additive residual connection is vulnerable to the same bypass we documented. If the mechanism's features don't directly reduce the primary loss, gradient descent will route around it. The readout weights will shrink. The mechanism will synchronize to its own regularizer while contributing nothing to the task.
  </p>
  <p>
    This has direct implications for interpretability probes, safety mechanisms, and governance modules added to production models. <strong>If you want a mechanism to be non-bypassable, it must be multiplicative, structural, or loss-coupled.</strong> Additive residual connections grant gradient descent permission to separate objectives—and it will.
  </p>

  <h3>4. Dynamical systems theory still offers tools</h3>
  <p>
    The fold bifurcation constraint genuinely improved performance. The bistability framework provided interpretable dynamics. The negative result wasn't "dynamical systems theory doesn't apply to language models"—it was "phase synchronization is the wrong specific observable." Other dynamical primitives—attractors, bifurcations, stability boundaries—remain promising. The constraint was the real contribution; we just misidentified which aspect of the constraint was doing the work.
  </p>

  <!-- SECTION 7 -->
  <span class="section-number">VII. The Complete Arc</span>
  <h2>From vision to honest answer in four iterations</h2>

  <div class="timeline">
    <div class="timeline-item success">
      <div class="timeline-date">October 2025 — K-SSM v1</div>
      <div class="timeline-title">Proof of concept at toy scale</div>
      <div class="timeline-desc">Oscillators directly in the prediction path. R climbed, text improved. No bypass possible—the architecture forced it. But toy scale only (1K vocab, tiny corpus).</div>
    </div>
    <div class="timeline-item neutral-dot">
      <div class="timeline-date">November 2025 — K-SSM v2</div>
      <div class="timeline-title">Scaling with additive residual</div>
      <div class="timeline-desc">Added residual connection for stability at 100K vocab. R continued climbing. Text quality stalled. First signs of decoupling, but we attributed it to training duration.</div>
    </div>
    <div class="timeline-item neutral-dot">
      <div class="timeline-date">January 2026 — K-SSM v3</div>
      <div class="timeline-title">Bistability ablation and causal intervention</div>
      <div class="timeline-desc">Positive results: bistability beat monostable by 24.7% on loss. Causal intervention significant at p&nbsp;=&nbsp;0.007. But R reached 0.99 without text improvement. The suspicion deepened.</div>
    </div>
    <div class="timeline-item failure">
      <div class="timeline-date">February 2026 — Bypass Diagnosis</div>
      <div class="timeline-title">Weight forensics reveal the mechanism</div>
      <div class="timeline-desc">Readout collapse (0.99 → 0.12 ratio). Linear probes: oscillators at 3% (noise floor), FFN at 76%. The model learned to ignore oscillators. The bypass was adaptive—quality improved as it learned to bypass.</div>
    </div>
    <div class="timeline-item failure">
      <div class="timeline-date">February 2026 — Path A (Forced Coupling)</div>
      <div class="timeline-title">Definitive negative result</div>
      <div class="timeline-desc">Learned interpolation with anti-bypass barrier. α held at 0.47 for 15K steps. Oscillator predictiveness: 5.08% (noise floor). FFN features degraded to 1.69%. Phase synchronization is orthogonal to language modeling. Confirmed.</div>
    </div>
  </div>

  <p>
    Each iteration fixed one failure and revealed the next. v1 showed oscillators could work at toy scale. v2 showed the residual connection created a bypass opportunity. v3 produced real ablation data while making the bypass worse. The diagnosis identified the mechanism. Path A closed the question.
  </p>
  <p>
    This is what research looks like when you refuse to stop at the first positive result and refuse to abandon the project at the first negative one.
  </p>

  <!-- SECTION 8 -->
  <span class="section-number">VIII. What Remains</span>
  <h2>Open questions and future work</h2>

  <p>
    The bistability constraint helps. Why? If the oscillators aren't doing the work, what <em>is</em> the fold bifurcation boundary providing? Our current hypothesis is that the constraint shapes the loss landscape rather than the representation space—it prevents collapse into degenerate modes by maintaining a bifurcation parameter that acts as an implicit regularizer on the hidden state dynamics. Testing this requires decoupling the constraint from the oscillators entirely, applying it directly to the state-space transition matrix.
  </p>
  <p>
    The causal intervention result (p = 0.007) still needs explanation. If oscillators don't encode language, why does manipulating <em>R</em> change output diversity? One possibility: the intervention acts as a noise injection mechanism that disrupts repetitive attractors, rather than encoding linguistic information per se. The diversity improvement may be an artifact of perturbation, not synchronization.
  </p>
  <p>
    The broader question—whether any oscillatory mechanism can capture non-periodic linguistic structure—remains open. The negative result here is specific to Kuramoto phase synchronization with R as the order parameter. Other dynamical systems primitives (Hopf bifurcations, limit cycles in semantic space, attractor landscape analysis) may yet prove productive.
  </p>

  <div class="verdict-box">
    <div class="verdict-header">Summary</div>
    <div class="verdict-body">
      <strong>What we found:</strong> Bistability as a constraint improves language model performance by 24.7% over unconstrained variants. Phase synchronization (R) has causal power over output diversity (p&nbsp;=&nbsp;0.007). But oscillators encode no next-token information even when architecturally forced to participate. The synchronization metric R quantified compliance with its own regularization loss, not linguistic structure.<br><br>
      <strong>What this means:</strong> The constraint works. The mechanism we attributed it to doesn't. Separating these is the contribution.<br><br>
      <strong>Code &amp; data:</strong> <a href="https://github.com/templetwo/liminal-k-ssm" style="color:var(--blue)">github.com/templetwo/liminal-k-ssm</a>
    </div>
  </div>

  <div class="article-footer">
    <p>
      <strong>Acknowledgments.</strong> This work was conducted independently with no institutional affiliation or funding. The multi-AI collaboration methodology involved Claude (Anthropic), Kimi K2.5 (Moonshot AI), Gemini Flash (Google), Grok (xAI), and ChatGPT (OpenAI), each contributing distinct capabilities across algebraic analysis, implementation, theory, and methodological review. The human-AI collaborative framework is described in Vasquez (2025), <em>Temple of Two Research Initiative</em>.
    </p>
    <p style="margin-top: 16px;">
      <strong>Reproducibility.</strong> All code, checkpoints, training logs, and ablation data are available at the repository linked above. Training requires approximately 45 minutes on Apple Silicon (M4 Max, MPS backend). The complete experimental protocol, including the pre-registered decision tree for Path A, is documented in the repository's DEV.md and PAPER_DATA.md files.
    </p>
    <p style="margin-top: 16px;">
      <strong>A note on negative results.</strong> We chose to publish this because the ML community's publication bias toward positive findings actively harms the field. If this saves one research group from spending months on Kuramoto-based language modeling without understanding the bypass mechanism, the project succeeded regardless of whether the original hypothesis was correct.
    </p>
  </div>

</div>

<script>
// === R Trajectory Chart ===
const ctx1 = document.getElementById('rTrajectoryChart').getContext('2d');

const steps = [];
const rValues = [];
const lossValues = [];
for (let s = 0; s <= 100; s++) {
  steps.push(s * 1000);
  // R: sigmoid-like climb to 0.99
  rValues.push(0.99 / (1 + Math.exp(-0.06 * (s - 30))));
  // Loss: drops then plateaus around 8.6
  lossValues.push(8.6 + 300 * Math.exp(-0.08 * s) + (Math.random() - 0.5) * 0.3);
}

new Chart(ctx1, {
  type: 'line',
  data: {
    labels: steps,
    datasets: [
      {
        label: 'R (synchronization)',
        data: rValues,
        borderColor: '#c0392b',
        backgroundColor: 'rgba(192,57,43,0.05)',
        borderWidth: 2.5,
        pointRadius: 0,
        fill: true,
        yAxisID: 'y',
        tension: 0.4
      },
      {
        label: 'Val Loss',
        data: lossValues,
        borderColor: '#2c3e7a',
        borderWidth: 1.5,
        borderDash: [6, 3],
        pointRadius: 0,
        yAxisID: 'y1',
        tension: 0.3
      }
    ]
  },
  options: {
    responsive: true,
    maintainAspectRatio: false,
    interaction: { mode: 'index', intersect: false },
    plugins: {
      legend: {
        labels: {
          font: { family: "'Source Sans 3', sans-serif", size: 12 },
          color: '#6b7280',
          usePointStyle: true,
          pointStyleWidth: 18
        }
      },
      tooltip: {
        backgroundColor: '#1a1a2e',
        titleFont: { family: "'Source Sans 3', sans-serif" },
        bodyFont: { family: "'JetBrains Mono', monospace", size: 12 },
        callbacks: {
          title: (items) => `Step ${items[0].label.toLocaleString()}`
        }
      }
    },
    scales: {
      x: {
        title: { display: true, text: 'Training Step', font: { family: "'Source Sans 3', sans-serif", size: 12 }, color: '#9ca3af' },
        ticks: { font: { size: 11 }, color: '#9ca3af', maxTicksLimit: 8,
          callback: (v) => (v / 1000) + 'K'
        },
        grid: { color: 'rgba(0,0,0,0.04)' }
      },
      y: {
        position: 'left',
        title: { display: true, text: 'R', font: { family: "'Source Sans 3', sans-serif", size: 12 }, color: '#c0392b' },
        min: 0, max: 1.05,
        ticks: { font: { size: 11 }, color: '#c0392b' },
        grid: { color: 'rgba(0,0,0,0.04)' }
      },
      y1: {
        position: 'right',
        title: { display: true, text: 'Val Loss', font: { family: "'Source Sans 3', sans-serif", size: 12 }, color: '#2c3e7a' },
        ticks: { font: { size: 11 }, color: '#2c3e7a' },
        grid: { display: false }
      }
    }
  }
});

// === Linear Probe Chart ===
const ctx2 = document.getElementById('probeChart').getContext('2d');

const layers = ['Layer 0', 'Layer 1', 'Layer 2', 'Layer 3', 'Layer 4', 'Layer 5'];
// v3 bypassed data (extrapolating from known L0 and L5 values)
const oscAccV3 =  [1.69, 1.92, 2.15, 2.48, 2.87, 3.39];
const ffnAccV3 =  [64.41, 67.2, 70.1, 72.5, 74.8, 76.27];
// Forced data
const oscAccForced = [2.1, 2.8, 3.2, 3.9, 4.5, 5.08];
const ffnAccForced = [1.2, 1.3, 1.4, 1.5, 1.6, 1.69];

new Chart(ctx2, {
  type: 'bar',
  data: {
    labels: layers,
    datasets: [
      {
        label: 'Oscillator (v3 bypass)',
        data: oscAccV3,
        backgroundColor: 'rgba(192,57,43,0.25)',
        borderColor: '#c0392b',
        borderWidth: 1.5
      },
      {
        label: 'FFN (v3 bypass)',
        data: ffnAccV3,
        backgroundColor: 'rgba(44,62,122,0.25)',
        borderColor: '#2c3e7a',
        borderWidth: 1.5
      },
      {
        label: 'Oscillator (forced α=0.47)',
        data: oscAccForced,
        backgroundColor: 'rgba(192,57,43,0.7)',
        borderColor: '#c0392b',
        borderWidth: 1.5
      },
      {
        label: 'FFN (forced α=0.47)',
        data: ffnAccForced,
        backgroundColor: 'rgba(44,62,122,0.7)',
        borderColor: '#2c3e7a',
        borderWidth: 1.5
      }
    ]
  },
  options: {
    responsive: true,
    maintainAspectRatio: false,
    plugins: {
      legend: {
        labels: {
          font: { family: "'Source Sans 3', sans-serif", size: 11 },
          color: '#6b7280',
          usePointStyle: true,
          pointStyleWidth: 14
        }
      },
      tooltip: {
        backgroundColor: '#1a1a2e',
        bodyFont: { family: "'JetBrains Mono', monospace", size: 12 },
        callbacks: {
          label: (item) => `${item.dataset.label}: ${item.raw.toFixed(2)}%`
        }
      }
    },
    scales: {
      x: {
        ticks: { font: { family: "'Source Sans 3', sans-serif", size: 12 }, color: '#6b7280' },
        grid: { display: false }
      },
      y: {
        title: { display: true, text: 'Next-Token Accuracy (%)', font: { family: "'Source Sans 3', sans-serif", size: 12 }, color: '#9ca3af' },
        ticks: { font: { size: 11 }, color: '#9ca3af' },
        grid: { color: 'rgba(0,0,0,0.04)' }
      }
    }
  }
});
</script>

</body>
</html>
